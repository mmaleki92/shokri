# بررسی کد: تحلیل نوت‌بوک‌های یادگیری ماشین

بررسی مختصر نوت‌بوک‌های Jupyter در مخزن `mmaleki92/shokri` با تمرکز روی پیاده‌سازی، پارامترها و نمودارها.

## ۱. نوت‌بوک‌های خوشه‌بندی (دیتاست مارپیچ)

- **مشکل**: استفاده از K-means با `n_clusters=3` برای داده مارپیچی مناسب نیست
- **پیشنهاد**: از DBSCAN استفاده کن که برای شکل‌های غیرکروی بهتر عمل می‌کنه

## ۲. نوت‌بوک‌های California Housing

- **نکته مثبت**: استفاده خوب از KNN و GridSearchCV
- **پیشنهاد**: به neural network، early stopping اضافه کن تا از overfitting جلوگیری بشه

## ۳. نوت‌بوک‌های Iris

- **مشکل جدی**: R² برابر ۱.۰۰۰۰ در `iris_linearregressionn.ipynb` احتمالاً نشانه data leakage هست
- **پیشنهاد**: استفاده از neural network برای دیتاست ساده Iris زیاده‌رویه
- **نکته مثبت**: پیاده‌سازی خوب SVM و نمایش ماتریس confusion

## ۴. نوت‌بوک‌های Penguins

- **مشکل**: در `penguins_regression_2x.ipynb`، خط رگرسیون ۱ بعدی برای داده ۲ بعدی اشتباهه
- **مشکوک**: دقت ۱۰۰٪ در `penguins_classification_5features.ipynb` احتمالاً نشونه data leakage هست

## ۵. نوت‌بوک‌های MNIST PCA

- **نکته مثبت**: انتخاب خوب مؤلفه‌های PCA و مقایسه RandomForest با شبکه عصبی

## پیشنهادهای کلی

### ۱. نمایش مرز تصمیم‌گیری
- برای مدل‌های دسته‌بندی، استفاده از توابع `plot_decision_boundary` مفیده

### ۲. ماتریس‌های Confusion
- پیاده‌سازی خوب انجام شده، اضافه کردن گزینه normalize می‌تونه مفید باشه

### ۳. مشکلات خاص برای رفع
- R² کامل (۱.۰) در رگرسیون Iris
- دقت ۱۰۰٪ در دسته‌بندی Penguins
- نمایش رگرسیون ۲ بعدی در penguins_regression_2x

## نتیجه‌گیری

در کل، نوت‌بوک‌ها نشون میدن که درک خوبی از مفاهیم یادگیری ماشین داری. برای بهبود:

۱. **انتخاب مدل**: الگوریتم‌های متناسب با ویژگی‌های داده انتخاب کن
۲. **اعتبارسنجی**: از cross-validation برای شناسایی overfitting استفاده کن
۳. **نمایش بصری**: نمودارهای مرز تصمیم و رگرسیون رو بهبود بده
۴. **Data Leakage**: مواردی که عملکرد به طرز مشکوکی عالیه رو بررسی کن

---
*تاریخ بررسی: ۱۴۰۳/۱۲/۱۱*